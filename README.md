# PART I

## Base

- [X] **Playing Atari with Deep Reinforcement Learning**
- [X] **Human-level control through deep reinforcement learning**
- [ ] **Rainbow: Combining Improvements in Deep Reinforcement Learning**

## Double

- [X] **Deep Reinforcement Learning with Double Q-learning (double)**

## Dueling

- [X] **Dueling Network Architectures for Deep Reinforcement Learning (dueling)**

## Manipulate Experience Replay

- [X] **PRIORITIZED EXPERIENCE REPLAY (PER)**
- [X] Prioritized Sequence Experience Replay (PSER)
- [ ] Hindsight Experience Replay

## Distributed

- [X] Massively Parallel Methods for Deep Reinforcement Learning (Gorila)
- [X] **Asynchronous Methods for Deep Reinforcement Learning (A3C)**
- [X] **REINFORCEMENT LEARNING THROUGH ASYNCHRONOUS ADVANTAGE ACTOR-CRITIC ON A GPU (GA3C)**
- [X] **EFFICIENT PARALLEL METHODS FOR DEEP REINFORCEMENT LEARNING (PAAC)**
- [X] ACCELERATED METHODS FOR DEEP REINFORCEMENT LEARNING
- [ ] IMPALA: Scalable Distributed Deep-RL with ImportanceWeighted Actor-Learner Architectures (IMPALA)

## Distributional

- [ ] Statistical Aspects of Wasserstein Distances
- [ ] The Cramer Distance as a Solution to Biased Wasserstein Gradients
- [X] **A Distributional Perspective on Reinforcement Learning (C51)**
- [ ] An Analysis of Categorical Distributional Reinforcement Learning
- [X] **Distributional Reinforcement Learning with Quantile Regression (QR-DQN)**
- [X] **Implicit Quantile Networks for Distributional Reinforcement Learning (IQN)**
- [X] **Fully Parameterized Quantile Function for Distributional Reinforcement Learning (FQF)**
- [X] **Statistics and Samples in Distributional Reinforcement Learning (ER-DQN)**
- [ ] **A distributional code for value in dopamine-based reinforcement learning**
- [ ] QUOTA: The Quantile Option Architecture for Reinforcement Learning

## Exploration

- [ ] Deep Exploration via Bootstrapped DQN
- [ ] Parameter Space Noise for Exploration
- [ ] Noisy Networks for Exploration

## Unclassified

- [ ] Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor



# PART II

## DPG

- [X] Deterministic Policy Gradient Algorithms
- [X] CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING
- [X] Distributed Distributional Deterministic Policy Gradients[1](https://arxiv.org/abs/1804.08617)

## FIM & NGD & TRM

- [X] Natural Gradient Works Efficiently in Learning [1](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.7280&rep=rep1&type=pdf)
- [X] A Natural Policy Gradient [1](https://papers.nips.cc/paper/2001/file/4b86abe48d358ecf194c56c69108433e-Paper.pdf)
- [ ] Approximately Optimal Approximate Reinforcement Learning [1](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/KakadeLangford-icml2002.pdf)
- [ ] New insights and perspectives on the natural gradient method
- [X] **Trust Region Policy Optimization**
- [X] **High-Dimensional Continuous Control Using Generalized Advantage Estimation**
- [ ] **Generative Adversarial Imitation Learning**
- [ ] Sample Efficient Actor-Critic with Experience Replay
- [ ] Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation
- [ ] TensorFlow Agents: Efficient Batched Reinforcement Learning in TensorFlow
- [ ] Proximal Policy Optimization Algorithms
- [ ] Emergence of Locomotion Behaviours in Rich Environments
- [ ] Implementation Matters in Deep Policy Gradients: A Case Study on PPO and TRPO

# FLANKS

## ATTENTION

- [X] CBAM - CBAM: Convolutional Block Attention Module

## CNN

### BACKBONES

- [ ] CSP - CSPNet: A New Backbone that can Enhance Learning Capability of CNN


### NECKS

- [X] SPP - Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition
- [X] FPN - Feature Pyramid Networks for Object Detection
- [X] PAN - Path Aggregation Network for Instance Segmentation


## OBJECT DETECTION


